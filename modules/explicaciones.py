import streamlit as st

def mostrar_explicacion_regresion_lineal():
    st.title("ğŸ“ˆ ExplicaciÃ³n paso a paso de RegresiÃ³n Lineal Simple ğŸ“ˆ")

    st.markdown(r"""
**1. Â¿QuÃ© es la RegresiÃ³n Lineal Simple?**  
Es un mÃ©todo estadÃ­stico que modela la relaciÃ³n entre:
- Variable dependiente \(Y\)
- Variable independiente \(X\)
mediante una lÃ­nea recta.
""")
    st.latex(r"Y = \beta_0 + \beta_1 X + \varepsilon")

    st.markdown(r"""
**2. Objetivo**  
Encontrar \(\beta_0\) y \(\beta_1\) que minimicen el **error cuadrÃ¡tico** entre los valores observados \(Y_i\) y los predichos \(\hat{Y}_i\).
""")

    with st.expander("ğŸ”¢ Paso 1: CÃ¡lculo de medias", expanded=True):
        st.markdown(r"""
Se calcula la media de \(X\) y de \(Y\):
""")
        st.latex(r"\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i \quad;\quad \bar{Y} = \frac{1}{n} \sum_{i=1}^n Y_i")

    with st.expander("ğŸ”¢ Paso 2: CÃ¡lculo de la pendiente \(\beta_1\)", expanded=False):
        st.markdown(r"""
Dos fÃ³rmulas equivalentes:
""")
        st.latex(r"\beta_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}")
        st.latex(r"\beta_1 = \frac{n \sum X_i Y_i - \sum X_i \sum Y_i}{n \sum X_i^2 - (\sum X_i)^2}")

    with st.expander("ğŸ”¢ Paso 3: CÃ¡lculo del intercepto \(\beta_0\)", expanded=False):
        st.latex(r"\beta_0 = \bar{Y} - \beta_1 \bar{X}")

    st.markdown(r"""
**4. EcuaciÃ³n final del modelo**  
Se sustituye para obtener:\n
\[
\hat{Y} = \beta_0 + \beta_1 X
\]
""")

    with st.expander("ğŸ“Š Paso 5: EvaluaciÃ³n del modelo", expanded=False):
        st.markdown(r"""
**Metricas comunes**:
- **Error CuadrÃ¡tico Medio (MSE):**
""")
        st.latex(r"MSE = \frac{1}{n} \sum_{i=1}^n (Y_i - \hat{Y}_i)^2")
        st.markdown(r"""
- **Coeficiente de DeterminaciÃ³n \(R^2\):**
""")
        st.latex(r"R^2 = 1 - \frac{\sum (Y_i - \hat{Y}_i)^2}{\sum (Y_i - \bar{Y})^2}")

    st.markdown(r"""
**6. InterpretaciÃ³n**  
- Si \(\beta_1 > 0\), \(Y\) tiende a aumentar con \(X\).  
- Si \(\beta_1 < 0\), \(Y\) tiende a disminuir con \(X\).  
- \(R^2\) cerca de 1 indica buen ajuste; cerca de 0, poco explicativo.

**7. Uso prÃ¡ctico**  
Una vez calculados \(\beta_0\) y \(\beta_1\), se predice \(Y\) para nuevos \(X\) con la ecuaciÃ³n del modelo.
""")



def mostrar_explicacion_k_medias():
    st.title("ğŸ§  ExplicaciÃ³n paso a paso del algoritmo K-medias ğŸ§ " )

    st.markdown(r"""
    K-medias es un algoritmo de clustering que agrupa datos en \(k\) clusters basados en la distancia a centroides.

    ### Proceso general:

    1. Se elige el nÃºmero de clusters \(k\).
    2. Se inicializan los centroides (aleatoriamente o por mÃ©todos heurÃ­sticos).
    3. Cada punto se asigna al cluster cuyo centroide estÃ¡ mÃ¡s cercano (usualmente distancia euclidiana).
    4. Se recalculan los centroides como la medias de los puntos asignados a cada cluster.
    5. Se repiten los pasos 3 y 4 hasta que las asignaciones no cambien (convergencia).
    
    ### CaracterÃ­sticas:

    - Puede trabajar con datos multidimensionales.
    - Es sensible a la inicializaciÃ³n de centroides.
    - No garantiza un Ã³ptimo global, pero suele converger rÃ¡pido.
    - Es comÃºn usar reducciÃ³n dimensional para visualizar clusters cuando hay muchas variables.

    ### Aplicaciones:

    - SegmentaciÃ³n de clientes.
    - Agrupamiento de documentos.
    - DetecciÃ³n de patrones en datos.
    """)
def mostrar_explicacion_k_modas():
    st.title("âœ¨ ExplicaciÃ³n de K-modas âœ¨")
    st.markdown("""
    K-modas es una tÃ©cnica de clustering para datos categÃ³ricos. Similar a K-medias, pero en lugar de usar medias y distancia euclidiana, usa modas (valores mÃ¡s frecuentes) y una medida de disimilitud basada en conteo de diferencias.

    ### Proceso bÃ¡sico:
    1. Se asignan los modos iniciales por cluster segÃºn la moda en los datos conocidos.
    2. Cada punto se asigna al cluster cuyo modo tiene menor nÃºmero de diferencias con el dato.
    3. Se recalculan los modos con las asignaciones actuales.
    4. Se repite hasta convergencia.
    5. Se imputan los valores faltantes usando el modo del cluster asignado.

    ### Aplicaciones comunes:
    - Datos categÃ³ricos puros.
    - SegmentaciÃ³n de clientes por atributos categÃ³ricos.
    - AnÃ¡lisis de comportamiento con variables no numÃ©ricas.

    ### Diferencias con K-medias:
    - K-medias usa medias y distancia euclidiana (numÃ©rico).
    - K-modas usa modas y distancia por conteo de diferencias (categÃ³rico).

    """)
def mostrar_explicacion_id3():
    st.title("ğŸŒ² ExplicaciÃ³n del Ãrbol de DecisiÃ³n ID3 ğŸŒ²")
    st.markdown(r"""
**Proceso de construcciÃ³n del Ãrbol de DecisiÃ³n ID3**

1. **IntroducciÃ³n**  
El algoritmo ID3 construye un Ã¡rbol de decisiÃ³n que clasifica datos buscando, en cada nodo, el atributo que maximiza la ganancia de informaciÃ³n (reducciÃ³n de entropÃ­a).

2. **EntropÃ­a**  
Mide la impureza o incertidumbre de un conjunto de datos:
""")
    st.latex(r"E(S) = - \sum_{i=1}^{c} p_i \log_k(p_i)")
    st.markdown(r"""
- \(S\): conjunto de datos.  
- \(c\): nÃºmero de clases.  
- \(p_i\): proporciÃ³n de ejemplos en la clase \(i\).

Si todas las instancias son de la misma clase, \(E(S)=0\). Si estÃ¡n uniformemente distribuidas, \(E(S)\) es mÃ¡ximo.

3. **Ganancia de InformaciÃ³n**  
Cuantifica cuÃ¡nto disminuye la entropÃ­a al dividir por un atributo \(A\):
""")
    st.latex(r"G(S,A) = E(S) - \sum_{v \in Valores(A)} \frac{|S_v|}{|S|}\,E(S_v)")
    st.markdown(r"""
- \(S_v\): subconjunto de \(S\) donde el atributo \(A\) toma el valor \(v\).

Se elige el atributo con **mayor** \(G(S,A)\) (o **menor** entropÃ­a condicional).

4. **Proceso recursivo**  
- Calcular \(E(S)\).  
- Para cada atributo restante, calcular \(G(S,A)\).  
- Crear un nodo con el mejor atributo y dividir \(S\) segÃºn sus valores.  
- Repetir en cada rama hasta que:  
  1. Todas las instancias queden en la misma clase (entropÃ­a = 0).  
  2. No queden atributos.

5. **ConstrucciÃ³n del Ã¡rbol**  
- **Nodos internos**: representan pruebas sobre atributos.  
- **Ramas**: representan los valores de esos atributos.  
- **Hojas**: contienen las clases finales.

6. **ExtracciÃ³n de reglas**  
Cada camino desde la raÃ­z hasta una hoja produce una regla del tipo:  
Si A1 = v1 y A2 = v2 â€¦, entonces Clase = c
"""
)

def mostrar_explicacion_regresion_multiple():
    st.title("ğŸ“Š ExplicaciÃ³n paso a paso de RegresiÃ³n Lineal MÃºltiple ğŸ“Š")

    st.markdown("### 1. Â¿QuÃ© es la RegresiÃ³n Lineal MÃºltiple?")
    st.markdown("""
Es una extensiÃ³n de la regresiÃ³n lineal simple que modela la relaciÃ³n entre una variable dependiente \( Y \) y mÃºltiples variables independientes \( X_1, X_2, ..., X_n \).
    """)
    st.latex(r"Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_n X_n + \varepsilon")
    st.markdown("""
Donde:  
- \( \beta_0 \): Intercepto.  
- \( \beta_j \): Coeficientes asociados a cada variable independiente.  
- \( \varepsilon \): Error aleatorio o residual.
    """)

    st.markdown("---")
    st.markdown("### 2. Objetivo")
    st.markdown("""
Encontrar los coeficientes \( \boldsymbol{\beta} \) que minimicen la suma de errores cuadrÃ¡ticos entre los valores observados y los valores predichos.
    """)
    st.latex(r"\min_{\boldsymbol{\beta}} \left( \mathbf{Y} - \mathbf{X} \boldsymbol{\beta} \right)^T \left( \mathbf{Y} - \mathbf{X} \boldsymbol{\beta} \right)")

    st.markdown("---")
    st.markdown("### 3. RepresentaciÃ³n matricial")

    st.markdown("El modelo se puede escribir como:")
    st.latex(r"\mathbf{Y} = \mathbf{X} \boldsymbol{\beta}")

    st.markdown("Donde:")
    st.latex(r"""
\mathbf{Y} =
\begin{bmatrix}
Y_1 \\
Y_2 \\
\vdots \\
Y_m
\end{bmatrix},
\quad
\mathbf{X} =
\begin{bmatrix}
1 & X_{11} & X_{12} & \cdots & X_{1n} \\
1 & X_{21} & X_{22} & \cdots & X_{2n} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & X_{m1} & X_{m2} & \cdots & X_{mn}
\end{bmatrix},
\quad
\boldsymbol{\beta} =
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\beta_2 \\
\vdots \\
\beta_n
\end{bmatrix}
""")

    st.markdown("---")
    st.markdown("### 4. CÃ¡lculo de los coeficientes")
    st.markdown("Usamos la ecuaciÃ³n normal para obtener los coeficientes Ã³ptimos:")
    st.latex(r"\boldsymbol{\beta} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}")
    st.markdown("Esta fÃ³rmula proporciona los valores de \( \boldsymbol{\beta} \) que minimizan la suma de los errores cuadrÃ¡ticos.")

    st.markdown("---")
    st.markdown("### 5. InterpretaciÃ³n de coeficientes")
    st.markdown("""
- \( \beta_0 \): Valor esperado de \( Y \) cuando todas las variables \( X_j = 0 \).  
- \( \beta_j \): Cambio esperado en \( Y \) por unidad de cambio en \( X_j \), manteniendo las demÃ¡s variables constantes.
    """)

    st.markdown("---")
    with st.expander("ğŸ”¢ Ejemplo prÃ¡ctico", expanded=False):
        st.markdown("Ejemplo: predecir el precio de una casa con base en su tamaÃ±o (mÂ²) y nÃºmero de habitaciones:")
        st.latex(r"\widehat{Precio} = 31.04 + 1.40 \times TamaÃ±o + 2.50 \times Habitaciones")
        st.markdown("""
- Por cada metro cuadrado adicional, el precio aumenta en 1.40 unidades monetarias.  
- Por cada habitaciÃ³n adicional, el precio aumenta en 2.50 unidades monetarias.
        """)

    
