import streamlit as st

# -----------------------------
# Explicaci贸n: Regresi贸n Lineal Simple
# -----------------------------

def mostrar_explicacion_regresion_lineal():
    st.title(" Explicaci贸n paso a paso de Regresi贸n Lineal Simple")

    st.markdown(r"""
**1. 驴Qu茅 es la Regresi贸n Lineal Simple?**  
Es un m茅todo estad铆stico que modela la relaci贸n entre:
- Variable dependiente \(Y\)
- Variable independiente \(X\)
mediante una l铆nea recta.
""")
    st.latex(r"Y = \beta_0 + \beta_1 X + \varepsilon")

    st.markdown(r"""
**2. Objetivo**  
Encontrar \(\beta_0\) y \(\beta_1\) que minimicen el **error cuadr谩tico** entre los valores observados \(Y_i\) y los predichos \(\hat{Y}_i\).
""")

    with st.expander(" Paso 1: C谩lculo de medias", expanded=True):
        st.markdown(r"""Se calcula la media de \(X\) y de \(Y\):""")
        st.latex(r"\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i \quad;\quad \bar{Y} = \frac{1}{n} \sum_{i=1}^n Y_i")

    with st.expander(" Paso 2: C谩lculo de la pendiente \(\beta_1\)", expanded=False):
        st.markdown(r"Dos f贸rmulas equivalentes:")
        st.latex(r"\beta_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}")
        st.latex(r"\beta_1 = \frac{n \sum X_i Y_i - \sum X_i \sum Y_i}{n \sum X_i^2 - (\sum X_i)^2}")

    with st.expander(" Paso 3: C谩lculo del intercepto \(\beta_0\)", expanded=False):
        st.markdown(r"\(\beta_0 = \bar{Y} - \beta_1 \bar{X}\)")

    st.markdown(r"""
**4. Ecuaci贸n final del modelo**  
\[
\hat{Y} = \beta_0 + \beta_1 X
\]
""")

    with st.expander(" Paso 5: Evaluaci贸n del modelo", expanded=False):
        st.markdown("**M茅tricas comunes:**")
        st.latex(r"MSE = \frac{1}{n} \sum_{i=1}^n (Y_i - \hat{Y}_i)^2")
        st.latex(r"R^2 = 1 - \frac{\sum (Y_i - \hat{Y}_i)^2}{\sum (Y_i - \bar{Y})^2}")

    st.markdown(r"""
**6. Interpretaci贸n**  
- \(\beta_1 > 0\): \(Y\) aumenta con \(X\).  
- \(\beta_1 < 0\): \(Y\) disminuye con \(X\).  
- \(R^2\) cercano a 1 indica buen ajuste.
""")

    with st.expander(" Paso 7: Uso pr谩ctico", expanded=False):
        st.markdown(r"""
```python
# Ejemplo de predicci贸n
X_nuevo = [1, valor_X]
pred = X_nuevo @ [beta_0, beta_1]
```
""")

# -----------------------------
# Explicaci贸n: Regresi贸n Lineal M煤ltiple
# -----------------------------

def mostrar_explicacion_regresion_multiple():
    st.title(" Explicaci贸n paso a paso de Regresi贸n Lineal M煤ltiple")

    st.markdown(r"""
**1. 驴Qu茅 es la Regresi贸n Lineal M煤ltiple?**  
Extiende la regresi贸n lineal simple a varias variables independientes \(X_1, \,..., X_p\) para predecir \(Y\).

Ecuaci贸n general:  
\[
Y = \beta_0 + \beta_1 X_1 + ... + \beta_p X_p + \varepsilon
\]

- \(\beta_0\): intercepto.  
- \(\beta_j\): coeficientes de \(X_j\).  
- \(\varepsilon\): t茅rmino de error.
""")

    st.markdown(r"""
**2. Objetivo**  
Minimizar la suma de cuadrados de residuos (RSS):
\[
RSS = \sum_{i=1}^n (Y_i - (\beta_0 + \sum_{j=1}^p \beta_j X_{ij}))^2
\]
""")

    with st.expander(" Paso 3: Ecuaci贸n Normal", expanded=True):
        st.markdown("F贸rmula de MCO (ecuaci贸n normal):")
        st.latex(r"\hat{\boldsymbol{\beta}} = (X^T X)^{-1} X^T Y")

    with st.expander(" Paso 4: Coeficientes", expanded=False):
        st.markdown(r"Se extraen los coeficientes del vector \(\hat{\boldsymbol{\beta}}\):")
        st.latex(r"\hat{\beta}_j = [(X^T X)^{-1} X^T Y]_j")

    with st.expander(" Paso 5: Evaluaci贸n", expanded=False):
        st.markdown("**M茅tricas:**")
        st.latex(r"MSE = \frac{1}{n} \sum (Y_i - \hat{Y}_i)^2")
        st.latex(r"R^2 = 1 - \frac{\sum (Y_i - \hat{Y}_i)^2}{\sum (Y_i - \bar{Y})^2}")

    st.markdown(r"""
**6. Interpretaci贸n**  
- \(\beta_j\): cambio en \(Y\) por unidad de \(X_j\).  
- \(R^2\): cercano a 1 indica buen ajuste.
""")

    with st.expander(" Paso 7: Uso pr谩ctico", expanded=False):
        st.markdown(r"""
```python
# Ejemplo de predicci贸n
X_nuevo = [1, x1, ..., xp]
pred = X_nuevo @ beta_hat
```
""")

# -----------------------------
# Explicaci贸n: K-means
# -----------------------------

def mostrar_explicacion_k_means():
    st.title(" Explicaci贸n paso a paso de K-means")
    st.markdown(r"""
**Proceso general**:  
1. Elegir \(k\).  
2. Inicializar centroides.  
3. Asignar cada punto al centroide m谩s cercano.  
4. Recalcular centroides como medias.  
5. Repetir hasta convergencia.

**Caracter铆sticas**: r谩pido, sensible a inicializaci贸n, no garantiza 贸ptimo global.

**Aplicaciones**: segmentaci贸n de clientes, clustering de documentos.
""")

# -----------------------------
# Explicaci贸n: K-modes
# -----------------------------

def mostrar_explicacion_k_modas():
    st.title(" Explicaci贸n paso a paso de K-modes (K-modas)")
    st.markdown(r"""
**Proceso b谩sico**:  
1. Inicializar modas.  
2. Asignar puntos al modo m谩s similar.  
3. Recalcular modas.  
4. Repetir hasta convergencia.

Usa conteo de diferencias para datos categ贸ricos; imputa faltantes con modas.
""")

# -----------------------------
# Explicaci贸n: rbol de Decisi贸n ID3
# -----------------------------

def mostrar_explicacion_id3():
    st.title(" Explicaci贸n paso a paso de rbol de Decisi贸n ID3")
    st.markdown(r"""
**1. Entrop铆a**  
\(E(S) = -\sum_i p_i \log_k(p_i)\)

**2. Ganancia de Informaci贸n**  
\(G(S,A) = E(S) - \sum_v \frac{|S_v|}{|S|} E(S_v)\)

**3. Selecci贸n**  
Elegir atributo con mayor \(G(S,A)\) (o menor \(E(S|A)\)).

**4. Recursi贸n**  
Repetir hasta nodos puros o sin atributos.

**5. Reglas**  
Cada camino ra铆zhoja define una regla.
""")

# Ejemplo de uso:
# if st.sidebar.button("Mostrar explicaciones"):
#     mostrar_explicacion_regresion_lineal()
#     mostrar_explicacion_regresion_multiple()
#     mostrar_explicacion_k_means()
#     mostrar_explicacion_k_modas()
#     mostrar_explicacion_id3()
