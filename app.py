import streamlit as st
import importlib

st.set_page_config(page_title="App de Predicci칩n", layout="wide")

st.sidebar.title("游늭 Men칰 de algoritmos")
opcion = st.sidebar.selectbox(
    "Selecciona el algoritmo que deseas ejecutar:",
    (
        "츼rbol de Decisi칩n",
        "K-means",
        "Regresi칩n Lineal",
        "Regresi칩n M칰ltiple",
    )
)

mostrar_explicacion = st.sidebar.button("Mostrar explicaci칩n ID3")

def mostrar_explicacion_id3():
    st.title("Explicaci칩n del algoritmo 츼rbol de Decisi칩n ID3")

    st.markdown("""
    # Proceso de construcci칩n del 츼rbol de Decisi칩n ID3

    1. **Introducci칩n**  
    El algoritmo ID3 construye un 치rbol de decisi칩n que clasifica datos usando el criterio de m치xima ganancia de informaci칩n, basada en la entrop칤a.

    2. **Entrop칤a**  
    Mide la impureza o incertidumbre de un conjunto de datos.  
    F칩rmula:  
    $$
    Entrop칤a(S) = - \sum_{i=1}^c p_i \log_2(p_i)
    $$
    donde:  
    - \(S\) es el conjunto de datos,  
    - \(c\) es el n칰mero de clases,  
    - \(p_i\) es la proporci칩n de ejemplos en la clase \(i\).

    Si todos los datos pertenecen a una sola clase, la entrop칤a es 0 (conjunto puro).  
    Si las clases est치n distribuidas uniformemente, la entrop칤a es m치xima.

    3. **Ganancia de Informaci칩n**  
    Mide cu치nto reduce la entrop칤a un atributo al dividir los datos.  
    F칩rmula:  
    $$
    Ganancia(S, A) = Entrop칤a(S) - \sum_{v \in Valores(A)} \frac{|S_v|}{|S|} Entrop칤a(S_v)
    $$
    donde:  
    - \(S_v\) es el subconjunto de \(S\) donde el atributo \(A\) toma el valor \(v\).

    Elegimos el atributo con m치xima ganancia para dividir.

    4. **Proceso Recursivo**  
    Calcula la entrop칤a y ganancia para cada atributo.  
    Escoge el atributo con mayor ganancia para crear un nodo.  
    Divide el conjunto seg칰n los valores del atributo.  
    Repite recursivamente en cada subconjunto hasta que:  
    - Todos los ejemplos son de la misma clase (entrop칤a = 0).  
    - No quedan m치s atributos para dividir.

    5. **Construcci칩n del 츼rbol**  
    El nodo ra칤z es el atributo con mayor ganancia.  
    Cada rama corresponde a un valor del atributo.  
    Las hojas contienen las clases finales.

    6. **Extracci칩n de Reglas**  
    Cada camino desde la ra칤z hasta una hoja representa una regla.  
    La regla concatena las condiciones de cada nodo en el camino.  

    Ejemplo:  
    `Si Nivel acad칠mico = Mag칤ster y Estrato socioecon칩mico = Medio y 츼rea de estudio = Ingenier칤a, entonces Categor칤a = Titular`
    """)

if mostrar_explicacion:
    mostrar_explicacion_id3()
else:
    # Carga el m칩dulo correspondiente seg칰n selecci칩n
    modulos = {
        "츼rbol de Decisi칩n": "modules.arbol_decision",
        "K-means": "modules.k_means",
        "Regresi칩n Lineal": "modules.regresion_lineal",
        "Regresi칩n M칰ltiple": "modules.regresion_multiple",
    }

    modulo_seleccionado = modulos.get(opcion)

    if modulo_seleccionado:
        mod = importlib.import_module(modulo_seleccionado)
        if hasattr(mod, "run"):
            mod.run()
        elif hasattr(mod, "procesar_arbol_decision"):
            mod.procesar_arbol_decision()
    else:
        st.warning("Selecciona una opci칩n v치lida.")
